{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic defect analysis of Electroluminescence imaging through YOLOV5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Download the library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "\n",
    "!pip install tensorflow==2.3.1 \n",
    "\n",
    "!pip install tensorboard==2.4.1\n",
    "!pip install torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # YOLOv5 implemented using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image #this is to render predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Divide the dataset into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import choice\n",
    "import shutil\n",
    "\n",
    "#arrays to store file names\n",
    "imgs =[]\n",
    "xmls =[]\n",
    "\n",
    "#setup dir names\n",
    "trainPath = 'C:/Users/asim/Desktop/BaseData/Training/yolov5-main/dataset/train'\n",
    "valPath = 'C:/Users/asim/Desktop/BaseData/Training/yolov5-main/dataset/val'\n",
    "crsPath = 'C:/Users/asim/Desktop/BaseData/Training/yolov5-main/Data/ts/' #dir where images and annotations stored\n",
    "\n",
    "#setup ratio (val ratio = rest of the files in origin dir after splitting into train and test)\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "\n",
    "\n",
    "#total count of imgs\n",
    "totalImgCount = len(os.listdir(crsPath))/2\n",
    "\n",
    "#soring files to corresponding arrays\n",
    "for (dirname, dirs, files) in os.walk(crsPath):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.txt'):\n",
    "            xmls.append(filename)\n",
    "        else:\n",
    "            imgs.append(filename)\n",
    "\n",
    "\n",
    "#counting range for cycles\n",
    "countForTrain = int(len(imgs)*train_ratio)\n",
    "countForVal = int(len(imgs)*val_ratio)\n",
    "print(\"training images are : \",countForTrain)\n",
    "print(\"Validation images are : \",countForVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a folder segregate the dataset into train and validation folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainimagePath = 'C:/Users/asim/Desktop/BaseData/Training/yolov5-main/dataset/images/train'\n",
    "trainlabelPath = 'C:/Users/asim/Desktop/BaseData/Training/yolov5-main/dataset/labels/train'\n",
    "valimagePath = 'C:/Users/asim/Desktop/BaseData/Training/yolov5-main/dataset/images/val'\n",
    "vallabelPath = 'C:/Users/asim/Desktop/BaseData/Training/yolov5-main/dataset/labels/val'\n",
    "#cycle for train dir\n",
    "for x in range(countForTrain):\n",
    "\n",
    "    fileJpg = choice(imgs) # get name of random image from origin dir\n",
    "    fileXml = fileJpg[:-4] +'.txt' # get name of corresponding annotation file\n",
    "\n",
    "    #move both files into train dir\n",
    "    #shutil.move(os.path.join(crsPath, fileJpg), os.path.join(trainimagePath, fileJpg))\n",
    "    #shutil.move(os.path.join(crsPath, fileXml), os.path.join(trainlabelPath, fileXml))\n",
    "    shutil.copy(os.path.join(crsPath, fileJpg), os.path.join(trainimagePath, fileJpg))\n",
    "    shutil.copy(os.path.join(crsPath, fileXml), os.path.join(trainlabelPath, fileXml))\n",
    "\n",
    "\n",
    "    #remove files from arrays\n",
    "    imgs.remove(fileJpg)\n",
    "    xmls.remove(fileXml)\n",
    "\n",
    "\n",
    "\n",
    "#cycle for test dir   \n",
    "for x in range(countForVal):\n",
    "\n",
    "    fileJpg = choice(imgs) # get name of random image from origin dir\n",
    "    fileXml = fileJpg[:-4] +'.txt' # get name of corresponding annotation file\n",
    "\n",
    "    #move both files into train dir\n",
    "    #shutil.move(os.path.join(crsPath, fileJpg), os.path.join(valimagePath, fileJpg))\n",
    "    #shutil.move(os.path.join(crsPath, fileXml), os.path.join(vallabelPath, fileXml))\n",
    "    shutil.copy(os.path.join(crsPath, fileJpg), os.path.join(valimagePath, fileJpg))\n",
    "    shutil.copy(os.path.join(crsPath, fileXml), os.path.join(vallabelPath, fileXml))\n",
    "    \n",
    "    #remove files from arrays\n",
    "    imgs.remove(fileJpg)\n",
    "    xmls.remove(fileXml)\n",
    "\n",
    "#rest of files will be validation files, so rename origin dir to val dir\n",
    "#os.rename(crsPath, valPath)\n",
    "shutil.move(crsPath, valPath) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset.yaml\n",
    "move the dataset’s dataset.yaml file to the /content/yolov5/data directory.\n",
    "This file contains information required by YOLO to train the model on the custom data.\n",
    "image.png\n",
    "\n",
    "At the end of the training, two files should be saved in yolov5/runs/train/exp/weights: last.pt and best.pt. We’ll use best.pt.\n",
    "Explore the metrics recorded during training, I suggest you use TensorBoard, a very interactive exploration tool:¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --img 415 --batch 16 --epochs 100 --data data.yaml --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights runs/train/exp7/weights/best.pt --img 416 --conf 0.1 --source runs/train/exp7/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imageName in glob.glob('runs/detect/exp15/*.jpg'): #assuming JPG\n",
    "    display(Image(filename=imageName))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
